# 线性回归算法详解

线性回归是机器学习中最基础也是最重要的算法之一。

## 算法原理

线性回归试图学习一个线性模型来尽可能准确地预测实值输出标记。

### 数学表达

对于单变量线性回归：
$$y = \theta_0 + \theta_1 x$$

对于多变量线性回归：
$$y = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n$$

也可以用向量形式表示：
$$y = \theta^T x$$

## 损失函数

使用均方误差（MSE）作为损失函数：
$$J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$$

## 参数求解

### 正规方程

$$\theta = (X^T X)^{-1} X^T y$$

### 梯度下降

$$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)$$

## Python 实现

```python
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# 生成示例数据
X = np.random.randn(100, 1)
y = 2 * X.squeeze() + 1 + 0.1 * np.random.randn(100)

# 训练模型
model = LinearRegression()
model.fit(X, y)

# 预测
y_pred = model.predict(X)

# 可视化
plt.scatter(X, y, alpha=0.5)
plt.plot(X, y_pred, 'r-', linewidth=2)
plt.xlabel('X')
plt.ylabel('y')
plt.title('线性回归示例')
plt.show()

print(f"斜率: {model.coef_[0]:.2f}")
print(f"截距: {model.intercept_:.2f}")
```

## 应用场景

- 房价预测
- 销售预测
- 股价分析
- 医学诊断

## 优缺点

### 优点
- 简单易懂
- 计算效率高
- 不容易过拟合
- 可解释性强

### 缺点
- 只能处理线性关系
- 对异常值敏感
- 特征工程要求较高

## 改进方法

- **岭回归** - 添加L2正则化
- **Lasso回归** - 添加L1正则化
- **弹性网络** - 结合L1和L2正则化